{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f155644",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deap in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from deap) (1.26.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install deap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80690e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "\n",
    "# Load dataset from CSV\n",
    "data = pd.read_csv('./eclipse.csv')\n",
    "\n",
    "# Convert 'post' column to binary\n",
    "data['post_binary'] = data['post'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Prepare the feature matrix (X) and the target vector (y)\n",
    "X = data.drop(columns=['plugin', 'filename', 'pre', 'post', 'post_binary'])  # Dropping non-numeric and target columns\n",
    "y = data['post_binary']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be5fcd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the evaluation function for the Genetic Algorithm\n",
    "def evalFeatureSelection(individual):\n",
    "    selected_features = [i for i, val in enumerate(individual) if val == 1]\n",
    "    if len(selected_features) == 0:\n",
    "        return (0,)\n",
    "    \n",
    "    X_train_selected = X_train.iloc[:, selected_features]\n",
    "    X_test_selected = X_test.iloc[:, selected_features]\n",
    "    \n",
    "    clf = SVC()\n",
    "    clf.fit(X_train_selected, y_train)\n",
    "    y_pred = clf.predict(X_test_selected)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return (accuracy,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4361907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Genetic Algorithm using DEAP\n",
    "\n",
    "# Create the types\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# Register the functions\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=X_train.shape[1])\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"evaluate\", evalFeatureSelection)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5909b507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg     \tmin     \tmax     \n",
      "0  \t50    \t0.851976\t0.848332\t0.855255\n",
      "1  \t36    \t0.853216\t0.850535\t0.855255\n",
      "2  \t29    \t0.853958\t0.849276\t0.855255\n",
      "3  \t25    \t0.854644\t0.852423\t0.855884\n",
      "4  \t27    \t0.854953\t0.853682\t0.855884\n",
      "5  \t33    \t0.854947\t0.851479\t0.855884\n",
      "6  \t38    \t0.855066\t0.852738\t0.855884\n",
      "7  \t22    \t0.855312\t0.853996\t0.855884\n",
      "8  \t34    \t0.855595\t0.853996\t0.855884\n",
      "9  \t31    \t0.855702\t0.854311\t0.855884\n",
      "10 \t19    \t0.855752\t0.853367\t0.855884\n",
      "11 \t34    \t0.855677\t0.851794\t0.855884\n",
      "12 \t31    \t0.855733\t0.853682\t0.855884\n",
      "13 \t34    \t0.855576\t0.851164\t0.855884\n",
      "14 \t24    \t0.855651\t0.851479\t0.855884\n",
      "15 \t32    \t0.855765\t0.853996\t0.855884\n",
      "16 \t26    \t0.855802\t0.854626\t0.855884\n",
      "17 \t36    \t0.855765\t0.852423\t0.855884\n",
      "18 \t27    \t0.855582\t0.852738\t0.855884\n",
      "19 \t32    \t0.855714\t0.853052\t0.855884\n"
     ]
    }
   ],
   "source": [
    "# Run the Genetic Algorithm for feature selection:\n",
    "pop = toolbox.population(n=50)\n",
    "hof = tools.HallOfFame(1)\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)\n",
    "pop, logbook = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=20, stats=stats, halloffame=hof, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc80ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the Naive Bayes classifier using the best feature subset found:\n",
    "best_individual = hof[0]\n",
    "selected_features = [i for i, val in enumerate(best_individual) if val == 1]\n",
    "print(\"Best individual: \", best_individual)\n",
    "print(\"Number of selected features: \", len(selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00091382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "X_train_selected = X_train.iloc[:, selected_features]\n",
    "X_test_selected = X_test.iloc[:, selected_features]\n",
    "clf = SVC(probability=True)\n",
    "clf.fit(X_train_selected, y_train)\n",
    "\n",
    "# Test the classifier\n",
    "y_pred = clf.predict(X_test_selected)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e41d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# probabilities for the positive outcome\n",
    "y_pred_proba = clf.predict_proba(X_test_selected)[:,1]\n",
    "# Compute ROC curve and ROC area\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)  # false positive rate and true positive rate\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "#Save AUC values\n",
    "df = pd.DataFrame({\n",
    "    'AUC': roc_auc,\n",
    "    'FPR': fpr,\n",
    "    'TPR': tpr\n",
    "})\n",
    "df.to_csv('./AUC_Extracts/Eclipse/Eclipse_SVM_GAS.csv', index=False)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Eclipse-SVM-GAS')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
